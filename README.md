# üéôÔ∏è AudioScribe AI  
**Intelligent Meeting Summarizer powered by LLMs**

üé• **Watch the Demo Video:** https://drive.google.com/file/d/1tdjSdJ5f68b1kM4BtmGXcAnqv3-GFSl6/view?usp=sharing

AudioScribe AI is a Flask-based web application that automatically transcribes meeting audio and generates concise summaries, key discussion points, and action items using Large Language Models (LLMs) through **Ollama (Llama 3)**.

---

## üöÄ Features

- üéß **Automatic Transcription** ‚Äî Converts long audio or video meetings into text using `SpeechRecognition` and `pydub`.
- üßæ **LLM-Powered Summaries** ‚Äî Generates structured meeting summaries, action items, and task assignments using **Ollama‚Äôs Llama 3** model.
- üåê **Simple Web Interface** ‚Äî Drag-and-drop upload, live progress tracking, and downloadable transcript and summary files.
- üß† **Offline Local Processing** ‚Äî Works locally without sending data to external APIs.
- üß© **Scalable Pipeline** ‚Äî Modular design with Flask backend, background threading, and easy integration with other AI models.

---

## üèóÔ∏è Tech Stack

| Component | Technology |
|------------|-------------|
| **Frontend** | HTML, CSS, JavaScript (Vanilla) |
| **Backend** | Python (Flask) |
| **Speech-to-Text** | SpeechRecognition + pydub |
| **Summarization** | Ollama (Llama 3) |
| **Storage** | Local file system |
| **Environment** | Python 3.9+ |

---

## üß© Project Structure
- audioscribe-ai/
  - `app.py`
  - `large_audio_transcribe.py`
  - `ollama_summarize.py`
  - `templates/`
    - `index.html`
  - `uploads/` (temporary)
  - `outputs/` (transcripts & summaries)
  - `requirements.txt`
  - `README.md`
 
## ‚öôÔ∏è Installation

Follow these steps to set up and run **AudioScribe AI** locally üëá  

### 1Ô∏è‚É£ Clone the Repository  
- git clone https://github.com/<your-username>/audioscribe-ai.git
- cd audioscribe-ai
###2Ô∏è‚É£ Create a Virtual Environment
- python -m venv venv
- Activate it:

Windows:
- venv\Scripts\activate
macOS / Linux:
- source venv/bin/activate
### 3Ô∏è‚É£ Install Dependencies
- pip install -r requirements.txt
  
#### Make sure pip is up to date:
- pip install --upgrade pip
### 4Ô∏è‚É£ Install FFmpeg (Required by pydub)
#### Windows:

- Download from ffmpeg.org/download.html and add the bin folder to PATH

#### macOS:

- brew install ffmpeg
#### Ubuntu/Linux:

- sudo apt update && sudo apt install ffmpeg
### 5Ô∏è‚É£ Install and Run Ollama
- Download and install Ollama from ollama.ai/download.

- Pull a lightweight Llama model (recommended for most systems):

ollama pull llama3.2:1b
- Start the Ollama server:

ollama serve
- Keep this terminal running ‚Äî it hosts the local model.

### 6Ô∏è‚É£ (Optional) Configure Environment
Create a .env file in your root directory to override defaults:

- FLASK_ENV=development
- UPLOAD_FOLDER=uploads
- OUTPUT_FOLDER=outputs
- OLLAMA_MODEL=llama3.2:1b
### 7Ô∏è‚É£ Run the Flask Server
In a new terminal (with virtualenv active):

python app.py
Visit your app at üëâ http://localhost:5000

### 8Ô∏è‚É£ Upload & Summarize
- Drag & drop or select an audio/video file (.wav, .mp3, .m4a, .mp4, .avi)

- Wait for transcription & summarization to complete

- Download the Transcript and Summary files when ready

### 9Ô∏è‚É£ (Optional) Clean Up Files

rm -rf uploads/* outputs/*

---
## üß© API Endpoints
|Endpoint|	Method|	Description|
|------------|-------------|---------|
|/upload|	POST	|Uploads an audio/video file and starts processing|
|/status/<task_id>|	GET|	Returns JSON status and progress of transcription/summarization|
|/download/<task_id>/transcript	|GET|	Download transcript as text file|
|/download/<task_id>/summary	|GET	|Download AI-generated summary|
---

## üß© Example Output

#### Input:

Meeting audio (team discussing feature deadlines and responsibilities)

#### Output Summary (generated by Llama 3):
EXECUTIVE SUMMARY:
The team discussed project milestones and timeline adjustments.

KEY DECISIONS:
- Feature release postponed to next sprint.
- Design revisions approved.

ACTION ITEMS:
- John: Update UI mockups by Friday.
- Priya: Coordinate testing with QA team.



